{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d642f11-eafb-4a1d-a97f-93b8a810fd76",
   "metadata": {},
   "source": [
    "# BYOL - https://arxiv.org/pdf/2006.07733\n",
    "\n",
    "BYOL był już przedstawiany na liście 3. Nie ma więc sensu go tutaj przedstawiać kolejny raz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55681c8d-d91a-48b8-b52b-d3b9275c14d0",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa238754-6f61-42cb-99de-176a9c921370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from src.dataset import *\n",
    "from src.early_stopping import *\n",
    "from src.self_supervised_modules import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eef795-40f2-439f-b799-d686a7da8ca1",
   "metadata": {},
   "source": [
    "# Wczytanie danych do trenowania końcowego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad086ad-feaf-45fa-9807-5b4a03267d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('data_transform/subset0/data.npz')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31a08f-9e50-4ed5-bacb-a30c8547ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['images']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea47c0-55b7-4b58-a828-c4319cfdd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['labels']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321859aa-34ef-4afd-bb0f-67ac3cd59bc2",
   "metadata": {},
   "source": [
    "# Wczytanie danych do trenowania enkodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e818866-d89a-44d1-8136-7f2522665132",
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = np.load('data_transform/subset1/data.npz')['images']\n",
    "images2 = np.load('data_transform/subset2/data.npz')['images']\n",
    "images3 = np.load('data_transform/subset3/data.npz')['images']\n",
    "\n",
    "all_images = np.concatenate((images1, images2, images3))\n",
    "all_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeccdd1-c628-4c8e-a6eb-88e7e0380d78",
   "metadata": {},
   "source": [
    "# Wczytanie danych do walidacji klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713436b3-4db0-4745-a143-a4f82288fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = images4 = np.load('data_transform/subset4/data.npz')\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a72a5-d4c2-4096-b1c8-3a6d43a9bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = data_val['images']\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02f096-e76d-4bb0-884a-f6ad357d888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = data_val['labels']\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab080c-9966-427c-bacf-e75e1324e997",
   "metadata": {},
   "source": [
    "# Definicja augmentacji\n",
    "Ponieważ nasz zbiór danych to 10 najważniejszych obrazów to augmentacje, które zastosujemy muszą być identyczne dla każdego obrazu, żeby nie zatracić żadnej informacji.\n",
    "\n",
    "Pomysły na augmentację:\n",
    "1. Horizontal i Vertical flip obraza\n",
    "2. Rotacja\n",
    "\n",
    "Trudno wprowadzić więcej augmentacji gdyż ryzykujemy wówczas zbytnie zmienienie obrazów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fb507-5dcf-41b3-a027-c839dbd5a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(images, chance_flip_horizontal=0.5, chance_flip_vertical=0.5, chance_rotate=0.5, rotate_angle_max=45, rotate_angle_min=-45):\n",
    "    batch_size = images.shape[0]\n",
    "    no_images = images.shape[2]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        flip_horizontal = random.random() < chance_flip_horizontal\n",
    "        flip_vertical = random.random() < chance_flip_vertical\n",
    "        rotate = random.random() < chance_rotate\n",
    "        if rotate:\n",
    "            rorate_angle = random.randint(rotate_angle_min, rotate_angle_max)\n",
    "        \n",
    "        for j in range(no_images):\n",
    "            image_augment = images[i, 0, j]\n",
    "            if flip_horizontal:\n",
    "                image_augment = torchvision.transforms.functional.hflip(image_augment)\n",
    "            if flip_vertical:\n",
    "                image_augment = torchvision.transforms.functional.vflip(image_augment)\n",
    "            if rotate:\n",
    "                image_augment = image_augment.unsqueeze(0)\n",
    "                image_augment = torchvision.transforms.functional.rotate(image_augment, rorate_angle, fill=-1000)\n",
    "                image_augment = image_augment.squeeze()\n",
    "\n",
    "            images[i, 0, j] = image_augment\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001cd096-1b95-4e87-9fa6-73c480a93d05",
   "metadata": {},
   "source": [
    "# Definicja BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89a628-23a7-4ccf-a2f7-9e1fde5984dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL(nn.Module):\n",
    "    def __init__(self, encoder, tau: float = 0.999):\n",
    "        super(BYOL, self).__init__()\n",
    "        \n",
    "        # Initialize online network\n",
    "        self.online_encoder = encoder\n",
    "        self.online_projector = MLP(encoder.out_size, encoder.out_size, encoder.out_size, plain_last=False)\n",
    "        self.online_predictor = MLP(encoder.out_size, encoder.out_size, encoder.out_size, plain_last=True)\n",
    "        self.online_net = nn.Sequential(\n",
    "            self.online_encoder, \n",
    "            self.online_projector, \n",
    "            self.online_predictor,\n",
    "        )\n",
    "\n",
    "        # Initialize target network with frozen weights\n",
    "        self.target_encoder = self.copy_and_freeze_module(self.online_encoder)\n",
    "        self.target_projector = self.copy_and_freeze_module(self.online_projector)\n",
    "        self.target_net = nn.Sequential(self.target_encoder, self.target_projector)\n",
    "\n",
    "        self.tau = tau\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        x = x.cuda()\n",
    "        \n",
    "        t = apply_transformations(x)\n",
    "        t_prim = apply_transformations(x)\n",
    "\n",
    "        q = self.online_net(t)\n",
    "        q_sym = self.online_net(t_prim)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z_prim = self.target_net(t_prim)\n",
    "            z_prim_sym = self.target_net(t)\n",
    "\n",
    "        q = torch.cat([q, q_sym], dim=0)\n",
    "        z_prim = torch.cat([z_prim, z_prim_sym], dim=0)\n",
    "\n",
    "        return q, z_prim\n",
    "\n",
    "    @staticmethod\n",
    "    def byol_loss(q: Tensor, z_prim: Tensor) -> Tensor:\n",
    "        q = F.normalize(q, dim=-1)\n",
    "        z_prim = F.normalize(z_prim, dim=-1)\n",
    "        mult_sum = (q * z_prim).sum(dim = -1)\n",
    "        return (2 - 2 * mult_sum).mean()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_target_network(self) -> None:\n",
    "        for target_param, online_param in zip(self.target_net.parameters(), self.online_net.parameters()):\n",
    "            target_param.data = self.tau * target_param.data + (1 - self.tau) * online_param.data\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def copy_and_freeze_module(model: nn.Module) -> nn.Module:\n",
    "        model_copy = copy.deepcopy(model)\n",
    "        for param in model_copy.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "        return model_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7ebbd-631b-4def-b122-1b4d3ab5e950",
   "metadata": {},
   "source": [
    "# Trenowanie enkodera używanego w BYOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94b659-163a-4e60-addb-6360e2a64b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_byol(model, optimiser, dataloader, no_epochs=100, augment_params=None):\n",
    "    if augment_params is None:\n",
    "        augment_params = {}\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(no_epochs):\n",
    "        sum_loss = 0\n",
    "        for images in tqdm(dataloader):\n",
    "            q, z_prim = model(images)\n",
    "            \n",
    "            loss = BYOL.byol_loss(q, z_prim)\n",
    "    \n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "    \n",
    "            model.update_target_network()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch}: loss = {sum_loss:.3f}\")\n",
    "        losses.append(sum_loss)\n",
    "        \n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss\", fontsize=18)\n",
    "    plt.xlabel(\"Iteration\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4def-a7c7-45a8-ac1d-7c5bf06668f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "# 50 - default, 3 - for testing the code\n",
    "no_epochs = 50\n",
    "# no_epochs = 3\n",
    "\n",
    "unlabelled_dataset = UnlabelledDataset(all_images)\n",
    "unlabelled_dataloader = DataLoader(unlabelled_dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "\n",
    "encoder = Encoder()\n",
    "byol = BYOL(encoder).cuda()\n",
    "optimiser = optim.SGD(byol.parameters(), lr=0.001)\n",
    "\n",
    "train_byol(byol, optimiser, unlabelled_dataloader, no_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77979d5-5604-4f68-8073-52930ea234e6",
   "metadata": {},
   "source": [
    "# Trenowanie klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6df38-f4ff-4358-800b-66b6be16c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "train_dataset = LabelledDataset(X_train, y_train)\n",
    "val_dataset = LabelledDataset(X_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = SelfSupervisedClassifier(byol.online_encoder, 2).cuda()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "fit_classifier(\n",
    "    model=model, optimiser=optimiser, loss_fn=loss_fn,\n",
    "    train_dl=train_dl, val_dl=val_dl, epochs=50, early_stop=EarlyStopping(model_dir='model/byol', patience=5), print_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7001f1-fca3-4800-a8d8-c80233598790",
   "metadata": {},
   "source": [
    "# Liczenie metryk klasyfikacyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a3ba5-5350-449f-b940-7f317ee3ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LabelledDataset(X_val, y_val)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "calculate_metrics(model, val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
