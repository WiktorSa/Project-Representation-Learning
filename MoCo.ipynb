{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d642f11-eafb-4a1d-a97f-93b8a810fd76",
   "metadata": {},
   "source": [
    "# MoCO - Momentum Contrastum - https://arxiv.org/abs/1911.05722v3\n",
    "\n",
    "MoCo, or Momentum Contrast, jest kontrastową metodą self-supervised learning.\n",
    "\n",
    "Jako, że MoCo jest metodą kontrastową to naszym zadaniem będzie maksymalizacja podobieństwa pomiędzy pozytywnymi parami, a negatywnymi parami.\n",
    "\n",
    "Do zmierzenia prawdopodobieństwa pomiędzy parami często używa się InfoNCE, które używa iloczynu skalarnego do wyliczenia prawdopodobieństwa. Poniżej znaduje się wzór tej funkcji:\n",
    "\n",
    "<img src=\"notebook_images/InfoNCE_loss.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Powyższy koszt można też zrozumieć jako log loss softmax-based klasyfikatora, które próbuje sklasyfikować próbkę jako klasę pozytywną.\n",
    "\n",
    "Co więc wyróżnia MoCO od innych metod kontrastowych?\n",
    "\n",
    "Zdaniem twórców MoCo w metodach kontrastowych kluczem jest zbudowanie bardzo dużej bazy obrazów tak, żeby można było łatwo generować pozytywne i negatywne pary i na bazie nich wytrenować odpowiedni enkoder.\n",
    "\n",
    "Autorzy proponują następujące rozwiązanie:\n",
    "1. Zapisywanie użytych już obrazów w tzw. \"Dictionary\", które strukturalnie będzie kolejką. Dzięki temu podczas brania kolejnego batcha obrazów będziemy mieli bardzo dużo negatywnych przykładów\n",
    "2. Rozmiar naszej kolejki może być znacznie wyższy od rozmiaru batcha. Zalecane jest jednak ustawienie określonego rozmiaru i usuwanie najstarszego batcha. Wynika to z tego, że najstarszy batch jest najmniej aktualny ze wszystkich zapisanych batchy\n",
    "3. Używanie momentum update do aktualizacji wag key encodera. Aktualizacja wag została przedstawiona poniższym wzorem\n",
    "\n",
    "<img src=\"notebook_images/momentum_update.png\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "4. Po wytrenowaniu enkodera dalej bierzemy tylko query encoder\n",
    "\n",
    "Działanie algorytmu zostało dokładnie przedstawione na poniższym obrazku\n",
    "\n",
    "<img src=\"notebook_images/Moco_desc.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55681c8d-d91a-48b8-b52b-d3b9275c14d0",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa238754-6f61-42cb-99de-176a9c921370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from src.dataset import *\n",
    "from src.early_stopping import *\n",
    "from src.self_supervised_modules import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eef795-40f2-439f-b799-d686a7da8ca1",
   "metadata": {},
   "source": [
    "# Wczytanie danych do trenowania końcowego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad086ad-feaf-45fa-9807-5b4a03267d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('data_transform/subset0/data.npz')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31a08f-9e50-4ed5-bacb-a30c8547ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['images']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea47c0-55b7-4b58-a828-c4319cfdd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['labels']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321859aa-34ef-4afd-bb0f-67ac3cd59bc2",
   "metadata": {},
   "source": [
    "# Wczytanie danych do trenowania enkodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e818866-d89a-44d1-8136-7f2522665132",
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = np.load('data_transform/subset1/data.npz')['images']\n",
    "images2 = np.load('data_transform/subset2/data.npz')['images']\n",
    "images3 = np.load('data_transform/subset3/data.npz')['images']\n",
    "\n",
    "all_images = np.concatenate((images1, images2, images3))\n",
    "all_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeccdd1-c628-4c8e-a6eb-88e7e0380d78",
   "metadata": {},
   "source": [
    "# Wczytanie danych do walidacji klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713436b3-4db0-4745-a143-a4f82288fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = images4 = np.load('data_transform/subset4/data.npz')\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a72a5-d4c2-4096-b1c8-3a6d43a9bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = data_val['images']\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02f096-e76d-4bb0-884a-f6ad357d888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = data_val['labels']\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab080c-9966-427c-bacf-e75e1324e997",
   "metadata": {},
   "source": [
    "# Definicja augmentacji\n",
    "Ponieważ nasz zbiór danych to 10 najważniejszych obrazów to augmentacje, które zastosujemy muszą być identyczne dla każdego obrazu, żeby nie zatracić żadnej informacji.\n",
    "\n",
    "Pomysły na augmentację:\n",
    "1. Horizontal i Vertical flip obraza\n",
    "2. Rotacja\n",
    "\n",
    "Trudno wprowadzić więcej augmentacji gdyż ryzykujemy wówczas zbytnie zmienienie obrazów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fb507-5dcf-41b3-a027-c839dbd5a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(images, chance_flip_horizontal=0.5, chance_flip_vertical=0.5, chance_rotate=0.5, rotate_angle_max=45, rotate_angle_min=-45):\n",
    "    batch_size = images.shape[0]\n",
    "    no_images = images.shape[2]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        flip_horizontal = random.random() < chance_flip_horizontal\n",
    "        flip_vertical = random.random() < chance_flip_vertical\n",
    "        rotate = random.random() < chance_rotate\n",
    "        if rotate:\n",
    "            rorate_angle = random.randint(rotate_angle_min, rotate_angle_max)\n",
    "        \n",
    "        for j in range(no_images):\n",
    "            image_augment = images[i, 0, j]\n",
    "            if flip_horizontal:\n",
    "                image_augment = torchvision.transforms.functional.hflip(image_augment)\n",
    "            if flip_vertical:\n",
    "                image_augment = torchvision.transforms.functional.vflip(image_augment)\n",
    "            if rotate:\n",
    "                image_augment = image_augment.unsqueeze(0)\n",
    "                image_augment = torchvision.transforms.functional.rotate(image_augment, rorate_angle, fill=-1000)\n",
    "                image_augment = image_augment.squeeze()\n",
    "\n",
    "            images[i, 0, j] = image_augment\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001cd096-1b95-4e87-9fa6-73c480a93d05",
   "metadata": {},
   "source": [
    "# Definicja MoCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89a628-23a7-4ccf-a2f7-9e1fde5984dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoCo(nn.Module):\n",
    "    \"\"\"\n",
    "    Based on offical implementaion\n",
    "    https://github.com/facebookresearch/moco/blob/3631be074a0a14ab85c206631729fe035e54b525/moco/builder.py#L6\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, queue_size=4096, momentum=0.999, temperature=0.07):\n",
    "        super(MoCo, self).__init__()\n",
    "\n",
    "        self.queue_size = queue_size\n",
    "        self.momentum = momentum\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.encoder_query = copy.deepcopy(encoder)\n",
    "        self.encoder_key = copy.deepcopy(encoder)\n",
    "\n",
    "        # Create the queue and register it so it won't update during optimalisation\n",
    "        self.register_buffer(\"queue\", torch.randn(encoder.out_size, queue_size))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_query, param_key in zip(self.encoder_query.parameters(), self.encoder_key.parameters()):\n",
    "            param_key.data = param_key.data * self.momentum + param_query.data * (1. - self.momentum)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        batch_size = keys.shape[0]\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "\n",
    "        # enqueue and dequeue at the same time (transpose is needed)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        \n",
    "        # move pointer to the next oldest batch\n",
    "        ptr = (ptr + batch_size) % self.queue_size\n",
    "\n",
    "        # update saved queue pointer\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    def forward(self, im_query, im_key):\n",
    "        query = self.encoder_query(im_query) \n",
    "        query = nn.functional.normalize(query, dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            key = self.encoder_key(im_key)\n",
    "            key = nn.functional.normalize(key, dim=1)\n",
    "\n",
    "        # positive logits: Nx1\n",
    "        l_pos = torch.bmm(query.unsqueeze(1), key.unsqueeze(2)).squeeze(-1)\n",
    "        \n",
    "        # negative logits: NxK\n",
    "        l_neg = torch.mm(query, self.queue.clone().detach())\n",
    "        \n",
    "        # logits: Nx(1+K)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.temperature\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "\n",
    "        # dequeue and enqueue (operation with no gradient update so it can be done any time)\n",
    "        self._dequeue_and_enqueue(key)\n",
    "\n",
    "        return logits, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7ebbd-631b-4def-b122-1b4d3ab5e950",
   "metadata": {},
   "source": [
    "# Trenowanie enkodera używanego w MoCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94b659-163a-4e60-addb-6360e2a64b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_moco(model, optimiser, dataloader, loss_fn, no_epochs=100, augment_params=None):\n",
    "    if augment_params is None:\n",
    "        augment_params = {}\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(no_epochs):\n",
    "        sum_loss = 0\n",
    "        for images in tqdm(dataloader):\n",
    "            x_query = apply_transformations(images, **augment_params).cuda()\n",
    "            x_key = apply_transformations(images, **augment_params).cuda()\n",
    "    \n",
    "            logits, labels = model(x_query, x_key)\n",
    "    \n",
    "            loss = loss_fn(logits, labels)\n",
    "    \n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "    \n",
    "            model.momentum_update_key_encoder()\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch}: loss = {sum_loss:.3f}\")\n",
    "        losses.append(sum_loss)\n",
    "        \n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss\", fontsize=18)\n",
    "    plt.xlabel(\"Iteration\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4def-a7c7-45a8-ac1d-7c5bf06668f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "# 100 - default, 3 - for testing the code\n",
    "no_epochs = 100\n",
    "# no_epochs = 3\n",
    "\n",
    "unlabelled_dataset = UnlabelledDataset(all_images)\n",
    "unlabelled_dataloader = DataLoader(unlabelled_dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "\n",
    "encoder = Encoder()\n",
    "moco = MoCo(encoder).cuda()\n",
    "optimiser = optim.SGD(moco.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_moco(moco, optimiser, unlabelled_dataloader, loss_fn, no_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77979d5-5604-4f68-8073-52930ea234e6",
   "metadata": {},
   "source": [
    "# Trenowanie klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6df38-f4ff-4358-800b-66b6be16c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "train_dataset = LabelledDataset(X_train, y_train)\n",
    "val_dataset = LabelledDataset(X_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = SelfSupervisedClassifier(moco.encoder_query, 2).cuda()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "fit_classifier(\n",
    "    model=model, optimiser=optimiser, loss_fn=loss_fn,\n",
    "    train_dl=train_dl, val_dl=val_dl, epochs=50, early_stop=EarlyStopping(model_dir='model/moco', patience=5), print_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7001f1-fca3-4800-a8d8-c80233598790",
   "metadata": {},
   "source": [
    "# Liczenie metryk klasyfikacyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a3ba5-5350-449f-b940-7f317ee3ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LabelledDataset(X_val, y_val)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "calculate_metrics(model, val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
