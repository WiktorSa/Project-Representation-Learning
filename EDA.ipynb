{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5598d3b0-b7b6-4683-bcde-87e6b330e5dc",
   "metadata": {},
   "source": [
    "# EDA\n",
    "## Opis problemu\n",
    "Nowotwór płuc jest wiodącą przyczyną śmierci nowotworowych na świecie. Odpowiednie wcześnie wykrycie symptonów (w naszym przypadku będą to guzki płuc) zwiększa szanse pacjenta na wyleczenie.\n",
    "\n",
    "Wykrywanie guzków jest czasochłonne. Pojawia się więc pytanie czy możemy wykrywać guzki używając AI.\n",
    "\n",
    "Prostym z pozoru rozwiązaniem jest utworzenie dużego datasetu. Nie jest to jednak proste zadanie gdyż jak zostało już stwierdzone wykrywanie guzków jest czasochłonne. Utworzenie dużego datasetu wymaga pracy wielu osób i dużych funduszy, żeby opłacić te osoby.\n",
    "\n",
    "W naszym projekcie nie wnikniemy w wykrywanie guzków samych w sobie gdyż jest to problem zbyt zawiły i wykraczający znacznie poza zakres kursu \"Uczenie Reprezentacji\". Postaramy się natomiast sprawdzić czy model na postawie podanych koordynatów guzka jest w stanie powiedzieć czy to jest rzeczywiście guzek (co najmniej 3mm średnicy) czy nie jest to guzek (lub guzek jest poniżej 3mm średnicy). Można powiedzieć, że stworzymy weryfikator algorytmów do wykrywania guzków.\n",
    "\n",
    "Porównamy różne metody self-supervised learning i zobaczymy czy pozwalają lepiej one rozróżnieć guzki od nie-guzków.\n",
    "\n",
    "## Opis danych\n",
    "Dane zostały wzięte ze strony https://www.kaggle.com/datasets/avc0706/luna16  \n",
    "Pełny opis danych znajdziemy na tej stronie https://luna16.grand-challenge.org/\n",
    "\n",
    "Nasze dane składają się z trzech części:\n",
    "1. CT skanów, które przedstawiają płuca badanych osób\n",
    "2. Plik zawierający wszystkie wykryte guzki (co najmniej 3 mm średnicy) potwierdzone przez co najmniej 3 radiologów\n",
    "3. Plik zawierający wszystkie odrzucone guzki (brak wykrytego guzka lub guzek poniżej 3 mm średnicy) tzn. nie uzyskały weryfikacji co najmniej 3 radiologów\n",
    "\n",
    "Każdy guzek i nie-guzek ma lokalizację w tzw. world coordinates. Jest to uniwersalnie przyjęta metoda zapisu lokalizacji rzeczy na skanach CT. Szczegóły czym są dokładnie te koordynaty znajdują się tutaj https://theaisummer.com/medical-image-coordinates/\n",
    "\n",
    "WAŻNE - na danym skanie CT może być wiele guzków i nie-guzków\n",
    "\n",
    "Warto zauważyć, że nasz zbiór danych został w całości zweryfikowany przez radiologów. Podczas porównywania metod self-supervised learning zasymulujemy jednak sytuację w której większość danych nie będzie polabelowana (tzn. będzie tylko predykcja lokalizacji potencjalnego guzka)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8beeb-67f5-4712-aa3a-1eac2a935f21",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c967f9f-c9cf-4817-b330-0c2f0022a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dced862-dc71-4861-aad9-1931bab31d70",
   "metadata": {},
   "source": [
    "# Załadowanie pliku z annotacjami\n",
    "Będziemy korzystać z subsetu 0. Jeżeli chcesz odpalić dalej notebook to musisz pobrać ten subset stąd https://drive.google.com/drive/folders/1KqiXAkoAolDVdupdfkGHstMMHg7JIRlT?usp=sharing i umieścić go w folderze projektu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a948ac-c94d-413b-bbb2-09a9b1d605fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guzki zweryfikowane przez radiologów\n",
    "df_ann = pd.read_csv('data/annotations.csv')\n",
    "df_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf25ba-beed-4626-b1f6-121f412c9f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ann['seriesuid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bdfdcc-c1fa-4099-81d7-dfe17ca6dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guzki niezweryfikowane\n",
    "df_irrelevant_findings = pd.read_csv('data/annotations_excluded.csv')\n",
    "df_irrelevant_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29fb61-b082-45bf-ad6f-34720f7a8009",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_irrelevant_findings['seriesuid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9df8a-ff22-4287-92e8-f65f8816666b",
   "metadata": {},
   "source": [
    "Każdy plik z annotacjami ma 5 kolumn:\n",
    "1. seriesuid - numer identyfikacyjny pacjenta (pacjent może mieć więcej niż jeden skan CT\n",
    "2. coordX - położenie guzka (oś X, world coordinates)\n",
    "3. coordY - położenie guzka (oś Y, world coordinates)\n",
    "4. coordZ - położenie guzka (oś Z, world coordinates)\n",
    "5. diameter_mm - średnia guzka. W przypadku gdy nie ma guzka ta wartość wynosi -1. Na bazie tej wartości będziemy ustalać predykowaną klasę"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d86e03-fb8c-4817-bcee-e96a876d1f9a",
   "metadata": {},
   "source": [
    "# Złączenie danych i ustalenie danych pacjenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbe8d1-4a6d-4b08-8c0c-c6dc47350621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_ann, df_irrelevant_findings])\n",
    "df['class'] = df['diameter_mm'].apply(lambda x: 0 if x < 3 else 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90edf875-ac81-41e9-82e8-3dbda8f0931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6593595-b436-46a6-9750-f9fa8bf419b5",
   "metadata": {},
   "source": [
    "Nasz dataset jest niezbalansowany. Widzimy znaczną przewagę nie-guzków nad guzkami. Będziemy musieli uważać, żeby nasz model nie nauczył się wykrywać samych nie-guzków"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e906f-73f5-439c-83cb-087dceff9d8f",
   "metadata": {},
   "source": [
    "# Załadowanie obrazów\n",
    "Załadujemy dwa obrazy, żeby zobaczyć jak wyglądają dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7c180-7013-4a21-a253-f38bb0d1a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(f'data/images/subset0/*.mhd')\n",
    "# filenames to także identyfikator klienta\n",
    "filenames = [x.replace(f'data/images/subset0/', '').replace('.mhd', '') for x in filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c456780-0df0-48a9-a04f-4261722def3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37e460-9c84-40f0-a50c-3400702f16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9861e0-533e-4997-9130-2bceb3b2617f",
   "metadata": {},
   "source": [
    "Do wczytana obrazów użyjemy biblioteki SimpleITK  \n",
    "https://simpleitk.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd56cea-0c18-4272-b402-f7caea499247",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhd_file1 = sitk.ReadImage(filepaths[0])\n",
    "mhd_file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b40d11-9df7-4c52-94f3-7f4cb42f5356",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_scan1 = np.array(sitk.GetArrayFromImage(mhd_file1), dtype=np.float32)\n",
    "ct_scan1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1faa0-e262-41b0-a075-e1a4b3a50c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    plt.imshow(ct_scan1[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74186ee9-decc-4da4-8060-7940ef5609e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100, 10):\n",
    "    plt.imshow(ct_scan1[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba47f2-6638-420d-87bb-21867d215533",
   "metadata": {},
   "source": [
    "CT skany to tak naprawdę około 100 obrazów wymiaru 512x512, które pokazują nam płuca z różnych perspektyw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71e5c5-6ebd-420a-9dc3-7dc8e724e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhd_file2 = sitk.ReadImage(filepaths[1])\n",
    "ct_scan2 = np.array(sitk.GetArrayFromImage(mhd_file2), dtype=np.float32)\n",
    "ct_scan2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0702e-e12e-4230-b233-439b27dafde9",
   "metadata": {},
   "source": [
    "Mamy problem - każdy skan ma różną liczbę zdjęć. Możemy oczywiście próbować przetwarzać każdy obraz oddzielnie, ale znacząco wydłuży to trenowanie jak i samo użycie modelu będzie dłużej trwało. Dodatkowo kolejnym problemem będzie w jaki sposób odróżnić guzki od nie-guzków jeżeli na danym skanie może być kilka a nawet kilkanaście takich rzeczy wykrytych.\n",
    "\n",
    "Warto jednak zauważyć jedną rzecz - większość z tych skanów nie jest nam potrzebna, bo nie pokazuje niczego wartego uwagi. Jeżeli bylibyśmy w stanie ograniczyć się tylko do najważniejszych skanów (i jak można wycinków z tych skanów) to jesteśmy w stanie rozwiązać problem nierównej liczby zdjęć i zmniejszyć wymiarowość danych.\n",
    "\n",
    "Na pomoc przychodzą nam koordynaty w tzw. world coordinates. Bazując na nich jesteśmy w stanie zdobyć najbardziej istotne fragmenty ze skanów. Przetestujmy na naszych danych jak to będzie wyglądało"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9055b4-20d3-4e7d-9915-7e1c397b2a19",
   "metadata": {},
   "source": [
    "# Zmniejszenie wymiarowości danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1802cd5-2dcd-450a-8356-aa4ba984a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wymiar do którego chcemy zmniejszyć nasze skany CT\n",
    "DIMS_IRC = (10, 32, 32)\n",
    "\n",
    "mhd_file = mhd_file1\n",
    "ct_scan = ct_scan1\n",
    "# Weź dane właściwego pacjenta. Bierzemy tylko jeden odczyt z danego pacjenta nawet jeżeli jest ich kilka\n",
    "patient_data = df[df['seriesuid'] == filenames[0]].reset_index(drop=True).iloc[0]\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40808758-865a-4b12-9bb3-4db668ecd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bazowane na https://www.kaggle.com/code/mashruravi/pytorch-vs-cancer\n",
    "def get_scan_chunk(ct_scan, patient_data):\n",
    "    DIMS_IRC = (10, 32, 32)\n",
    "    \n",
    "    ct_scan.clip(-1000, 1000, ct_scan)\n",
    "        \n",
    "    origin_xyz = np.array(mhd_file.GetOrigin())\n",
    "    voxel_size_xyz = np.array(mhd_file.GetSpacing())\n",
    "    direction_matrix = np.array(mhd_file.GetDirection()).reshape(3, 3)\n",
    "    \n",
    "    coordX = patient_data['coordX']\n",
    "    coordY = patient_data['coordY']\n",
    "    coordZ = patient_data['coordZ']\n",
    "    \n",
    "    center_xyz = np.array([coordX, coordY, coordZ])\n",
    "    \n",
    "    cri = ((center_xyz - origin_xyz) @ np.linalg.inv(direction_matrix)) / voxel_size_xyz\n",
    "    cri = np.round(cri)\n",
    "    \n",
    "    irc = (int(cri[2]), int(cri[1]), int(cri[0]))\n",
    "    \n",
    "    slice_list = []\n",
    "    for axis, center_val in enumerate(irc):\n",
    "        start_index = int(round(center_val - DIMS_IRC[axis]/2))\n",
    "        end_index = int(start_index + DIMS_IRC[axis])\n",
    "    \n",
    "        if start_index < 0:\n",
    "            start_index = 0\n",
    "            end_index = int(DIMS_IRC[axis])\n",
    "        \n",
    "        if end_index > ct_scan.shape[axis]:\n",
    "            end_index = ct_scan.shape[axis]\n",
    "            start_index = int(ct_scan.shape[axis] - DIMS_IRC[axis])\n",
    "            \n",
    "        slice_list.append(slice(start_index, end_index))\n",
    "    \n",
    "    ct_scan_chunk = ct_scan[tuple(slice_list)]\n",
    "    return ct_scan_chunk\n",
    "\n",
    "ct_scan_chunk = get_scan_chunk(ct_scan, patient_data)\n",
    "ct_scan_chunk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3da992d-9918-4dce-847f-288b2f29d691",
   "metadata": {},
   "source": [
    "Udało nam się zmniejszyć wymiarowość danych. Zobaczmy teraz jak obrazy wyglądają. Warto pamiętać, że akurat w tym przypadku wykryto guzek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab53e2-1de4-493e-8392-c43b5f64b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    plt.imshow(ct_scan_chunk[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04a79c-6297-47cc-bd57-ec3df4964cd7",
   "metadata": {},
   "source": [
    "Widzimy, że obrazy teraz są znacznie bardziej informatywne niż wcześniej. Model się skupi na nauce najważniejszych informacji, a nie całych skanów.\n",
    "\n",
    "Zobaczmy ten sam proces przetwarzania danych, ale tym razem dla nie-guzka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429009f-13ad-4e4f-8fef-cf087fa95d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhd_file = mhd_file2\n",
    "ct_scan = ct_scan2\n",
    "# Weź dane właściwego pacjenta. Bierzemy tylko jeden odczyt z danego pacjenta nawet jeżeli jest ich kilka\n",
    "patient_data = df[df['seriesuid'] == filenames[1]].reset_index(drop=True).iloc[1]\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8b66a-7485-49fa-b8b9-90cad8d745fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_scan_chunk = get_scan_chunk(ct_scan, patient_data)\n",
    "ct_scan_chunk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979ce91-3caa-4a51-811c-6d1af343374a",
   "metadata": {},
   "source": [
    "Zobaczmy jak wyglądają skany gdy tego guzka nie ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f582c1d-d253-4658-807f-65d0462c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    plt.imshow(ct_scan_chunk[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e5424-a816-4ea7-b2de-08cc64fecb6e",
   "metadata": {},
   "source": [
    "Widzimy, że inaczej wyglądają oba skany. Znależliśmy więc efektywną metodę zmniejszenia wymiarowości danych tak żeby nie zatracić żadnej informacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8184c-7a16-4635-b33b-4e2ea2def8cc",
   "metadata": {},
   "source": [
    "# Podsumowanie\n",
    "Nasz problem jest tylko dotknięciem tematu wykrywania guzków płuc.\n",
    "\n",
    "Jednak nasza analiza pozwoliła nam zauważyć kilka rzeczy:\n",
    "1. Nasz problem jest niezbalansowany. Trzeba zwracać uwagę na to czy model rzeczywiście uczy się problemu czy tylko predykuje same nie-guzki\n",
    "2. Warto uważać na potencjalny wyciek danych. Jeżeli zmieszamy dane o wszystkich guzkach i nie-guzkach to wówczas jest szansa, że ten sam pacjent znajdzie się w zbiorze treningowym i zbiorze walidacyjnym. Dla bezpieczeństwa najlepiej jeżeli jeden subset zostanie w całości przeznaczony na walidację (co też autorzy datasetu zalecają)\n",
    "3. Mamy do czynienia z danymi medycznymi - trzeba bardzo uważać jak je przetwarzamy. Bardzo łatwo jest zrobić błąd w wyniku niewiedzy jak te dane działają\n",
    "4. Jesteśmy w stanie znacząco zmniejszyć wymiarowość danych. Koniecznym krokiem będzie odpowiedni preprocessing tych danych, gdyż nie chcemy trzymać 60 GB danych na naszym dysku."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
