{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d642f11-eafb-4a1d-a97f-93b8a810fd76",
   "metadata": {},
   "source": [
    "# DINO - self-DIstillation with NO labels - https://arxiv.org/pdf/2104.14294v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55681c8d-d91a-48b8-b52b-d3b9275c14d0",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa238754-6f61-42cb-99de-176a9c921370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from src.dataset import *\n",
    "from src.early_stopping import *\n",
    "from src.self_supervised_modules import *\n",
    "from src.utils import *\n",
    "import torch.nn.functional  as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eef795-40f2-439f-b799-d686a7da8ca1",
   "metadata": {},
   "source": [
    "# Wczytanie danych do trenowania końcowego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad086ad-feaf-45fa-9807-5b4a03267d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.load('data_transform/subset0/data.npz')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31a08f-9e50-4ed5-bacb-a30c8547ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train['images']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea47c0-55b7-4b58-a828-c4319cfdd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['labels']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321859aa-34ef-4afd-bb0f-67ac3cd59bc2",
   "metadata": {},
   "source": [
    "# Wczytanie danych do trenowania enkodera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e818866-d89a-44d1-8136-7f2522665132",
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = np.load('data_transform/subset1/data.npz')['images']\n",
    "images2 = np.load('data_transform/subset2/data.npz')['images']\n",
    "images3 = np.load('data_transform/subset3/data.npz')['images']\n",
    "\n",
    "all_images = np.concatenate((images1, images2, images3))\n",
    "all_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeccdd1-c628-4c8e-a6eb-88e7e0380d78",
   "metadata": {},
   "source": [
    "# Wczytanie danych do walidacji klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713436b3-4db0-4745-a143-a4f82288fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = images4 = np.load('data_transform/subset4/data.npz')\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a72a5-d4c2-4096-b1c8-3a6d43a9bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = data_val['images']\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02f096-e76d-4bb0-884a-f6ad357d888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = data_val['labels']\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab080c-9966-427c-bacf-e75e1324e997",
   "metadata": {},
   "source": [
    "# Definicja augmentacji\n",
    "DINO wymaga cropowania obrazów odpowiednio obrazów dla nauczyciela i studenta. Zaimplementujmy ten typ augmentacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096fb507-5dcf-41b3-a027-c839dbd5a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomResizedCrop3D(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 3\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, volume):\n",
    "        d, h, w = volume.shape  # Assuming volume is a 3D tensor (depth, height, width)\n",
    "        new_d, new_h, new_w = self.output_size\n",
    "\n",
    "        # Randomly crop\n",
    "        if d == new_d and h == new_h and w == new_w:\n",
    "            return volume  # No need to crop if dimensions match exactly\n",
    "\n",
    "        if d < new_d or h < new_h or w < new_w:\n",
    "            raise ValueError(f\"Requested crop size ({self.output_size}) larger than input size ({volume.shape})\")\n",
    "\n",
    "        # Randomly choose top left corner for cropping\n",
    "        top_d = random.randint(0, d - new_d)\n",
    "        top_h = random.randint(0, h - new_h)\n",
    "        top_w = random.randint(0, w - new_w)\n",
    "\n",
    "        # Perform cropping\n",
    "        cropped_volume = volume[top_d: top_d + new_d,\n",
    "                                top_h: top_h + new_h,\n",
    "                                top_w: top_w + new_w]\n",
    "\n",
    "        return cropped_volume\n",
    "\n",
    "def global_augment(images):\n",
    "    transform = RandomResizedCrop3D(output_size=(8, 28, 28))\n",
    "    tmp = []\n",
    "    for img in images:\n",
    "        tmp.append(transform(img.squeeze()))\n",
    "    \n",
    "    return torch.stack(tmp).unsqueeze(1)\n",
    "\n",
    "def local_augment(images):\n",
    "    transform = RandomResizedCrop3D(output_size=(4, 12, 12))\n",
    "    tmp = []\n",
    "    for img in images:\n",
    "        tmp.append(transform(img.squeeze()))\n",
    "    \n",
    "    return torch.stack(tmp).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001cd096-1b95-4e87-9fa6-73c480a93d05",
   "metadata": {},
   "source": [
    "# Definicja DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89a628-23a7-4ccf-a2f7-9e1fde5984dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINO(nn.Module):\n",
    "    def __init__(self, student_arch, teacher_arch, device: torch.device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            student_arch (nn.Module): ViT Network for student_arch\n",
    "            teacher_arch (nn.Module): ViT Network for teacher_arch\n",
    "            device: torch.device ('cuda' or 'cpu')\n",
    "        \"\"\"\n",
    "        super(DINO, self).__init__()\n",
    "    \n",
    "        self.student = student_arch(image_planes=8, images_width=28, images_height=28).to(device)\n",
    "        self.teacher = teacher_arch(image_planes=4, images_width=12, images_height=12).to(device)\n",
    "        self.teacher.load_state_dict(self.student.state_dict())\n",
    "\n",
    "        self.register_buffer('center', torch.zeros(1, 128).to('cuda'))\n",
    "\n",
    "        for param in self.teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    @staticmethod\n",
    "    def distillation_loss(student_output, teacher_output, center, tau_s, tau_t):\n",
    "        \"\"\"\n",
    "        Calculates distillation loss with centering and sharpening (function H in pseudocode).\n",
    "        \"\"\"\n",
    "        # Detach teacher output to stop gradients.\n",
    "        teacher_output = teacher_output.detach()\n",
    "\n",
    "        # Center and sharpen teacher's outputs\n",
    "        teacher_probs = F.softmax((teacher_output - center) / tau_t, dim=1)\n",
    "\n",
    "        # Sharpen student's outputs\n",
    "        student_probs = F.log_softmax(student_output / tau_s, dim=1)\n",
    "\n",
    "        # Calculate cross-entropy loss between student's and teacher's probabilities.\n",
    "        loss = - (teacher_probs * student_probs).sum(dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "    def teacher_update(self, beta: float):\n",
    "        for teacher_params, student_params in zip(self.teacher.parameters(), self.student.parameters()):\n",
    "            teacher_params.data.mul_(beta).add_(student_params.data, alpha=(1 - beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda52e3-6973-4507-89c4-8e94d6598752",
   "metadata": {},
   "source": [
    "# Definicja enkodera\n",
    "Niestety, ale DINO ma problem z użyciem enkodera zawartego w self_supervised_modules. Jesteśmy zmuszeni zaimplementować oddzielny enkoder specjalnie na potrzeby DINO (który jest modyfikacją uniwersalnego enkodera)\n",
    "\n",
    "Jednak mimo użycia innego enkodera końcowy model klasyfikacyjny będzie taki sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a2717-25bb-4bca-a974-37e78a1ac841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MEncoder(nn.Module):\n",
    "    def __init__(self, channels=None, out_size=128, image_planes=10, images_width=32, images_height=32):\n",
    "        super(MEncoder, self).__init__()\n",
    "        if channels is None:\n",
    "            channels = [1, 16, 32]\n",
    "        \n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        \n",
    "        # Keeping track of the dimensions\n",
    "        for i in range(len(channels) - 1):\n",
    "            self.model.add_module(f'conv_{i}', nn.Conv3d(channels[i], channels[i+1], kernel_size=3, padding=1))\n",
    "            self.model.add_module(f'relu_{i}', nn.ReLU())\n",
    "            self.model.add_module(f'maxpool_{i}', nn.MaxPool3d(2))\n",
    "        \n",
    "        self.model.add_module(\"adaptive_pool\", nn.AdaptiveAvgPool3d((1, 1, 1)))\n",
    "        self.model.add_module(\"flatten\", nn.Flatten())\n",
    "        self.model.add_module(\"linear\", nn.Linear(channels[-1], out_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7ebbd-631b-4def-b122-1b4d3ab5e950",
   "metadata": {},
   "source": [
    "# Trenowanie enkodera używanego w DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94b659-163a-4e60-addb-6360e2a64b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dino(dino: DINO,\n",
    "               data_loader: DataLoader,\n",
    "               optimizer: optim,\n",
    "               device: torch.device,\n",
    "               num_epochs,\n",
    "               tps=0.99,\n",
    "               tpt= 0.04,\n",
    "               beta= 0.9,\n",
    "               m= 0.9,\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    dino: DINO Module\n",
    "    data_loader (nn.Module): Dataloader for training\n",
    "    optimizer (nn.optimizer): Optimizer for optimization (SGD etc.)\n",
    "    defice (torch.device): 'cuda', 'cpu'\n",
    "    num_epochs: Number of Epochs\n",
    "    tps (float): tau for sharpening student logits\n",
    "    tpt: for sharpening teacher logits\n",
    "    beta (float): moving average decay \n",
    "    m (float): center moveing average decay\n",
    "    \"\"\"\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        dino.student.train()\n",
    "        dino.teacher.eval()\n",
    "    \n",
    "        loss_tab = []\n",
    "        for x in tqdm(data_loader):\n",
    "            x1 = global_augment(x)\n",
    "            x2 = local_augment(x)\n",
    "\n",
    "            student_output1, student_output2 = dino.student(x1.to(device)), dino.student(x2.to(device))\n",
    "            with torch.no_grad():\n",
    "                teacher_output1, teacher_output2 = dino.teacher(x1.to(device)), dino.teacher(x2.to(device))\n",
    "\n",
    "            # Compute distillation loss\n",
    "            loss = (dino.distillation_loss(teacher_output1.to(device), student_output2.to(device), dino.center, tps, tpt) +\n",
    "                    dino.distillation_loss(teacher_output2.to(device), student_output1.to(device), dino.center, tps, tpt)) / 2\n",
    "            loss_tab.append(loss.clone().cpu())\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.requires_grad = True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            dino.teacher_update(beta)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                dino.center = m * dino.center + (1 - m) * torch.cat([teacher_output1, teacher_output2], dim=0).mean(dim=0)\n",
    "\n",
    "        sum_loss = np.sum(loss_tab)\n",
    "        print(f\"Epoch: {epoch}, Loss: {sum_loss}\")\n",
    "        losses.append(sum_loss)\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss\", fontsize=18)\n",
    "    plt.xlabel(\"Iteration\", fontsize=14)\n",
    "    plt.ylabel(\"Loss\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4def-a7c7-45a8-ac1d-7c5bf06668f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "# 50 - default, 3 - for testing the code\n",
    "no_epochs = 50\n",
    "# no_epochs = 3\n",
    "\n",
    "unlabelled_dataset = UnlabelledDataset(all_images)\n",
    "dino = DINO(MEncoder, MEncoder, 'cuda')\n",
    "unlabelled_dataloader = DataLoader(unlabelled_dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "optimizer = optim.Adam(dino.parameters(), lr=0.00001)\n",
    "\n",
    "train_dino(dino, unlabelled_dataloader, optimizer,'cuda', no_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77979d5-5604-4f68-8073-52930ea234e6",
   "metadata": {},
   "source": [
    "# Trenowanie klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6df38-f4ff-4358-800b-66b6be16c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "\n",
    "train_dataset = LabelledDataset(X_train, y_train)\n",
    "val_dataset = LabelledDataset(X_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = SelfSupervisedClassifier(dino.student, 2).cuda()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "fit_classifier(\n",
    "    model=model, optimiser=optimiser, loss_fn=loss_fn,\n",
    "    train_dl=train_dl, val_dl=val_dl, epochs=50, early_stop=EarlyStopping(model_dir='model/dino', patience=5), print_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7001f1-fca3-4800-a8d8-c80233598790",
   "metadata": {},
   "source": [
    "# Liczenie metryk klasyfikacyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a3ba5-5350-449f-b940-7f317ee3ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = LabelledDataset(X_val, y_val)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "calculate_metrics(model, val_dl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
